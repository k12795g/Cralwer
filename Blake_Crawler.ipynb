{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---貼上要爬蟲的頁面的第一頁，注意網址要顯示格式為....../page/，輸入為空則結束\n",
      "---https://blake.com.tw/blog/category/taiwan/%E5%8D%97%E6%8A%95%E7%BE%8E%E9%A3%9F%E6%97%85%E8%A1%8C/page/\n",
      "---輸入爬取的網頁資料類型，食|衣|住|行|生活|育樂|醫療|養生\n",
      "---食\n",
      "---輸入要忽略的文章tag，輸入一個後enter輸入下個，輸入為空則輸入完畢\n",
      "---\n",
      "---開始爬取---\n",
      "NO.1 饗富餐廳｜南投竹山紫南宮附近甕仔雞推薦竟然還有滬川台菜可以選擇\n",
      "NO.2 竹香園甕缸雞｜南投竹山吃烤雞就吃這一家，有專屬停車場外還近竹山交流道與紫南宮\n",
      "NO.3 雲香園過橋米線｜清境山上玻璃屋景觀餐廳專賣雲南料理大推招牌菜檸檬包燒魚\n",
      "NO.4 清境宇星山莊｜可以看到山景與擁有三層兒童遊戲室的超狂清境親子民宿\n",
      "NO.5 清境美食要吃甚麼？｜9間清境必吃美食與必買伴手禮土雞城跟雲南料理都有\n",
      "NO.6 雞大王活蝦啤酒城｜海拔最高評價最多的清境烤雞餐廳可以點合菜桌菜\n",
      "NO.7 清境魯媽媽雲南擺夷料理｜來清境一定要來吃的雲南料理竟然是超美景觀餐廳\n",
      "---貼上要爬蟲的頁面的第一頁，注意網址要顯示格式為....../page/，輸入為空則結束\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#爬布雷克網站用的\n",
    "# {\n",
    "#     'Page-Title' : {\n",
    "#         'Title' : 'Page-Title',\n",
    "#         'Type' : '食|衣|住|行|生活|育樂|醫療|養生',\n",
    "#         'Author' : '網誌作者，如果有的話，沒有的話存成 無 ',\n",
    "#         'Date' : '文章發布日期',\n",
    "#         'Body' : '要用的文章，後續斷句使用',\n",
    "#         'Url' : '文章的連結'\n",
    "#     },\n",
    "# }\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "tag_list=[]\n",
    "Page_Title={}\n",
    "# Page_data={'Title':'','Type':'','Author':'無','Date' : '文章發布日期','Body' : '要用的文章，後續斷句使用','Url' : '文章的連結'}\n",
    "\n",
    "def Set_Data(url,Type,tag_list):\n",
    "    href=[]\n",
    "    Title=''\n",
    "    Author=''\n",
    "    Date=''\n",
    "    text=''\n",
    "    Number=1\n",
    "    count=0\n",
    "    while (True):\n",
    "        r=requests.get(url+str(Number))\n",
    "        Number+=1\n",
    "        soup=BeautifulSoup(r.text,\"html.parser\")\n",
    "        sel = soup.select(\"div.container div#content h2 a\") #各文章的標題連結html\n",
    "        if (not sel): break\n",
    "        for i in sel:\n",
    "            text='' #初始化合併過的內文\n",
    "            page=i.get('href')\n",
    "            page_r=requests.get(page) #開啟前面select/get到的網址\n",
    "            page_soup=BeautifulSoup(page_r.text,\"html.parser\")\n",
    "            \n",
    "            tag_check=False\n",
    "            for a in page_soup.select(\"div.post-header span.cat a\"): #若標籤存在於排除列表，則忽略此篇文章\n",
    "                if (a.text in tag_list):\n",
    "                    tag_check=True\n",
    "                    break\n",
    "            if (tag_check):continue\n",
    "                \n",
    "            Title=page_soup.select(\"div.post-header h1\")[0].text\n",
    "            Author=page_soup.select(\"div.author-content a\")[0].text\n",
    "            Date=page_soup.select(\"div.post-header span.post-date\")[0].text\n",
    "            Body_P=page_soup.select(\"div.post-entry p\")\n",
    "            for p in Body_P: #用以合併所有文本，排除圖片\n",
    "                if not p.find('img'):\n",
    "                    text+=p.text\n",
    "            Page_data={'Title':Title,'Type':Type,'Author':Author,'Date' : Date[1:],'Body' : text}\n",
    "            Page_Title[Title]=Page_data\n",
    "            \n",
    "            count+=1\n",
    "            print(\"NO.\"+str(count)+\" \"+Title)\n",
    "            \n",
    "while(1 ):\n",
    "    print(\"---貼上要爬蟲的頁面的第一頁，注意網址要顯示格式為....../page/，輸入為空則結束\\n---\",end='')\n",
    "    url=input()\n",
    "    if (not url): break\n",
    "    print(\"---輸入爬取的網頁資料類型，食|衣|住|行|生活|育樂|醫療|養生\\n---\",end='')\n",
    "    Type=input()\n",
    "    print(\"---輸入要忽略的文章tag，輸入一個後enter輸入下個，輸入為空則輸入完畢\\n---\",end='')\n",
    "    while (True):\n",
    "        tag_add=input()\n",
    "        if (tag_add):\n",
    "            tag_list.append(tag_add)\n",
    "            print(\"---\",end='')\n",
    "        else:\n",
    "            break\n",
    "    print(\"---開始爬取---\")\n",
    "    Set_Data(url,Type,tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---輸入創建的檔名，預設為'Crawl_from_Blake'\n",
      "test\n",
      "---結束---\n"
     ]
    }
   ],
   "source": [
    "print(\"---輸入創建的檔名，預設為'Crawl_from_Blake'\\n\",end='')\n",
    "name=input()\n",
    "if (not name):\n",
    "    name=\"Crawl_from_Blake\"\n",
    "    print(name)\n",
    "with open(name+\".json\",\"w\",encoding='utf-8')as f:\n",
    "    json.dump(Page_Title,f,indent=4,ensure_ascii=False) #存檔\n",
    "print(\"---結束---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
